{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar y probar un modelo de Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar modelo desde .h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo se puede cargar desde un archivo .h5. Al ejecutar el siguiente cuadro de código podremos cargar uno desde el explorador de archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya hay un modelo cargado ¿Quieres borrarlo? [s/n]: s\n",
      "Se ha borrado el modelo que se había cargado\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338e41206bca4ef5b05080c8b941f6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.h5', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import FileUpload, Output\n",
    "from tensorflow.keras import Model, models\n",
    "import json\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "if 'loaded_model' not in globals():\n",
    "    global loaded_model\n",
    "    loaded_model = None\n",
    "\n",
    "def mostrar_h5_upload():\n",
    "    h5_upload = FileUpload(accept= '.h5', \n",
    "    multiple=False)\n",
    "    display(h5_upload)\n",
    "    h5_upload.observe(handle_h5_upload, names='value')\n",
    "\n",
    "def handle_h5_upload(change):\n",
    "    *_, (_, f) = change['new'].items()\n",
    "    h5_content = f['content']\n",
    "    h5_uploaded_filepath = \"kerasModelUpload.h5\"\n",
    "    with open(h5_uploaded_filepath,\"w+b\") as h5_file:\n",
    "        h5_file.write(h5_content)\n",
    "    global loaded_model\n",
    "    loaded_model = models.load_model(h5_uploaded_filepath)\n",
    "    print(\"Modelo cargado correctamente\")\n",
    "    print(\"Ejecuta el siguiente cuadro de código para verlo...\")\n",
    "    os.remove(h5_uploaded_filepath)\n",
    "        \n",
    "if(loaded_model is not None):\n",
    "    answer = input(\"Ya hay un modelo cargado ¿Quieres borrarlo? [s/n]: \")\n",
    "    if answer == \"s\":\n",
    "        loaded_model = None\n",
    "        print(\"Se ha borrado el modelo que se había cargado\")\n",
    "        mostrar_h5_upload()\n",
    "    elif answer == \"n\":\n",
    "        print(\"No se ha borrado el modelo.\")\n",
    "    else:\n",
    "        print(\"No se ha borrado el modelo.\")\n",
    "else:\n",
    "    loaded_model=None\n",
    "    mostrar_h5_upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 126, 126, 4)       40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 42, 42, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 38, 38, 8)         808       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 6, 16)          6288      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 870       \n",
      "=================================================================\n",
      "Total params: 8,006\n",
      "Trainable params: 8,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien podemos cargar el modelo manualmente si sabemos el filepath del fichero .h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 124, 124, 20)      520       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 120, 120, 20)      10020     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 60, 60, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 58, 58, 40)        7240      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 56, 56, 40)        14440     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 40)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 80)        28880     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 24, 24, 80)        57680     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 22, 22, 80)        57680     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 11, 11, 80)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9680)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 600)               5808600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 1806      \n",
      "=================================================================\n",
      "Total params: 6,167,166\n",
      "Trainable params: 6,167,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "h5_filepath = \"ivanNetConAugmentation-final.h5\" # Sustituir por el filepath del archivo a cargar\n",
    "loaded_model = models.load_model(h5_filepath)\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo 'dataset.zip' ya existe en la carpeta '/home/carlos/projects/keras-cnn' así que no se ha descargado.\n",
      "El dataset está descomprimido en '/home/carlos/projects/keras-cnn/dataset'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Desde google.colab: pip install wget\n",
    "import wget\n",
    "import zipfile\n",
    "import sys\n",
    "\n",
    "# Code from: https://stackoverflow.com/questions/58125279/python-wget-module-doesnt-show-progress-bar#answer-61346454        \n",
    "def bar_progress(current, total, width=80):\n",
    "  progress_message = \"Downloading: %d%% [%d / %d] bytes\" % (current / total * 100, current, total)\n",
    "  # Don't use print() as it will print in new line every time.\n",
    "  sys.stdout.write(\"\\r\" + progress_message)\n",
    "  sys.stdout.flush()\n",
    "\n",
    "dataset_zip_filename = \"dataset.zip\"\n",
    "dataset_folder = dataset_zip_filename.replace(\".zip\", \"\")\n",
    "dataset_zip_url = \"https://zenodo.org/record/3902223/files/dataset-single-hand-finger-count.zip\"\n",
    "if(not os.path.isfile(dataset_zip_filename)):\n",
    "    print(f\"Se descargará el dataset desde '{dataset_zip_url}'\")\n",
    "    #command_wget = f\"wget --no-check-certificate -O {dataset_zip_filename} {dataset_zip_url}\"\n",
    "    wget.download(dataset_zip_url,dataset_zip_filename, bar=bar_progress)\n",
    "    #command_wget_res = os.system(command_wget)\n",
    "    if(os.path.isfile(dataset_zip_filename) and not os.path.exists(dataset_folder)):\n",
    "        print(f\"Dataset descargado con éxito en '{os.getcwd()}/{dataset_folder}'\")\n",
    "        zip_ref = zipfile.ZipFile(dataset_zip_filename, 'r')\n",
    "        zip_ref.extractall(dataset_folder)\n",
    "        zip_ref.close()\n",
    "        print(f\"El dataset se ha descomprimido en '{os.getcwd()}/{dataset_folder}'\")\n",
    "    \n",
    "else:\n",
    "    print(f\"El archivo '{dataset_zip_filename}' ya existe en la carpeta '{os.getcwd()}' así que no se ha descargado.\")\n",
    "    if(not os.path.exists(dataset_folder)):\n",
    "        print(f\"El archivo {dataset_zip_filename} no parece haber sido descomprimido, se procede a descomprimir.\")\n",
    "        zip_ref = zipfile.ZipFile(dataset_zip_filename, 'r')\n",
    "        zip_ref.extractall(dataset_folder)\n",
    "        zip_ref.close()\n",
    "        print(f\"El archivo {dataset_zip_filename} se ha descromprimido con éxito en '{os.getcwd()}/{dataset_folder}'\")\n",
    "    else:\n",
    "        print(f\"El dataset está descomprimido en '{os.getcwd()}/{dataset_folder}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14400 images belonging to 6 classes.\n",
      "Found 3600 images belonging to 6 classes.\n",
      "Found 3600 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "simple_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "dataset_folder=\"dataset\"\n",
    "batch_size=30\n",
    "\n",
    "train_dir=f\"{dataset_folder}/train\"\n",
    "test_dir=f\"{dataset_folder}/test\"\n",
    "val_dir=f\"{dataset_folder}/val\"\n",
    "\n",
    "train_set = simple_datagen.flow_from_directory(train_dir,\n",
    "                  batch_size=batch_size,\n",
    "                  class_mode='categorical',\n",
    "                  target_size=(128, 128),\n",
    "                  color_mode=\"grayscale\")\n",
    "\n",
    "test_set = simple_datagen.flow_from_directory(test_dir,\n",
    "                  batch_size=batch_size,\n",
    "                  class_mode = 'categorical',\n",
    "                  target_size = (128, 128),\n",
    "                  color_mode=\"grayscale\")\n",
    "\n",
    "val_set = simple_datagen.flow_from_directory(val_dir,\n",
    "                  batch_size=batch_size,\n",
    "                  class_mode = 'categorical',\n",
    "                  target_size = (128, 128),\n",
    "                  color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 26s 216ms/step - loss: 0.0155 - accuracy: 0.9956\n",
      "Precisión para el conjunto de Prueba: 0.995555579662323\n",
      "Pérdida para el conjunto de Prueba: 0.015504955314099789\n"
     ]
    }
   ],
   "source": [
    "metrics_test = loaded_model.evaluate(\n",
    "             test_set,\n",
    "             batch_size=30,\n",
    "             steps= test_set.n // 30,\n",
    "             verbose=1,\n",
    "             return_dict=True)\n",
    "\n",
    "acc_test    = metrics_test['accuracy']\n",
    "loss_test   = metrics_test['loss']\n",
    "\n",
    "print(f\"Precisión para el conjunto de Prueba: {acc_test}\")\n",
    "print(f\"Pérdida para el conjunto de Prueba: {loss_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar con data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14400 images belonging to 6 classes.\n",
      "Found 3600 images belonging to 6 classes.\n",
      "Found 3600 images belonging to 6 classes.\n",
      "Pasos por época: 480    Pasos de validación: 120\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "augmented_datagen = ImageDataGenerator(rescale = 1.0/255.,\n",
    "                                      width_shift_range=0.2,\n",
    "                                      height_shift_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      vertical_flip=True,\n",
    "                                      rotation_range=90)\n",
    "\n",
    "train_dir=f\"{dataset_folder}/train\"\n",
    "test_dir=f\"{dataset_folder}/test\"\n",
    "val_dir=f\"{dataset_folder}/val\"\n",
    "\n",
    "aug_train_set = augmented_datagen.flow_from_directory(train_dir,\n",
    "                  batch_size=30,\n",
    "                  class_mode='categorical',\n",
    "                  target_size=(128, 128),\n",
    "                  color_mode=\"grayscale\")\n",
    "\n",
    "aug_test_set = augmented_datagen.flow_from_directory(test_dir,\n",
    "                  batch_size=30,\n",
    "                  class_mode = 'categorical',\n",
    "                  target_size = (128, 128),\n",
    "                  color_mode=\"grayscale\")\n",
    "\n",
    "aug_val_set = augmented_datagen.flow_from_directory(val_dir,\n",
    "                  batch_size=30,\n",
    "                  class_mode = 'categorical',\n",
    "                  target_size = (128, 128),\n",
    "                  color_mode=\"grayscale\")\n",
    "\n",
    "batch_size = 30\n",
    "aug_steps_per_epoch = aug_train_set.n // batch_size\n",
    "aug_validation_steps = aug_val_set.n // batch_size\n",
    "print(\"Pasos por época: \" + str(aug_steps_per_epoch) + \"    Pasos de validación: \" + str(aug_validation_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 6s 48ms/step - loss: 0.1299 - accuracy: 0.9567\n"
     ]
    }
   ],
   "source": [
    "metrics_test_aug2 = loaded_model.evaluate(\n",
    "             aug_test_set,\n",
    "             batch_size=30,\n",
    "             steps= aug_test_set.n // batch_size,\n",
    "             verbose=1,\n",
    "             return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 6s 47ms/step - loss: 0.1380 - accuracy: 0.9533\n"
     ]
    }
   ],
   "source": [
    "metrics_test_aug2 = loaded_model.evaluate(\n",
    "             aug_val_set,\n",
    "             batch_size=30,\n",
    "             steps= aug_test_set.n // batch_size,\n",
    "             verbose=1,\n",
    "             return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 6s 48ms/step - loss: 0.1161 - accuracy: 0.9578\n"
     ]
    }
   ],
   "source": [
    "aug_train_set = loaded_model.evaluate(\n",
    "             aug_val_set,\n",
    "             batch_size=30,\n",
    "             steps= aug_test_set.n // batch_size,\n",
    "             verbose=1,\n",
    "             return_dict=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
